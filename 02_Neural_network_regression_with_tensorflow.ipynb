{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqODkmkClwtLK/jKYDu8yJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danish-khan962/Deep-Learning/blob/main/02_Neural_network_regression_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network Regression With Tensorflow**\n",
        "\n",
        "| Hyperparameter | Typical Values |\n",
        "|---|---|\n",
        "| **Input Layer Shape** | Same shape as number of features (e.g. 3 for #bedrooms, #bathrooms, #car spaces in housing price prediction |\n",
        "| Hidden Layers | Problem specific, minimum=1, maximum=unlimited |\n",
        "| Neurons per hidden layer | Problem specific, generally 10 to 100 |\n",
        "| Output layer shape | Same as desired prediction shape (e.g. 1 for house price) |\n",
        "| Hidden activation | Usually `ReLU`(rectified linear unit) |\n",
        "| Output activation | None, ReLU, logistic/tanh |\n",
        "| Loss Function | `MSE`(mean squared error) or `MAE`(mean absolute error)/`Huber`(combination of MAE/MSE) if outliers |\n",
        "| Optimizer | `SGD`(stochastic gradient descent), `Adam` |\n",
        "\n"
      ],
      "metadata": {
        "id": "FATWGggFm8jR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to Regression with Neural Networks in TensorFlow**\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, evern shorter.... predicting a number"
      ],
      "metadata": {
        "id": "iVeQ9liwoEaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing tensorflow\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version we're using: \", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgbQQVhCGsKB",
        "outputId": "a3129d88-2148-44d6-b1bc-c613167c7acd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version we're using:  2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data to view and fit"
      ],
      "metadata": {
        "id": "2qFwsBjVG1o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "gIZdpkC1G-7W",
        "outputId": "fe7dfb22-56e5-46b3-eb2f-02d8bb726d2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7e52a725ff90>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-3QkXyzHhAN",
        "outputId": "47f7cfa2-f52d-4177-e20d-e6a2fc783cab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.,  6.,  9., 12., 15., 18.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y == X + 10  # This is the relationship between our dependent variable(y) and independent variable(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gWfIP6OH_qW",
        "outputId": "4a03c14e-6aa3-4014-8cd7-725d91cb76ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and Output shapes"
      ],
      "metadata": {
        "id": "ZKU7vfH8IS9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant(654332)\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNbUt7WDJQI4",
        "outputId": "1572a574-308f-4448-ee73-e6bbe7b4557a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=654332>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### From this above house price cell we know about the shapes of both features and labels. Here `house_info` is our feature deriving the `house_price` which is our label our output we can say."
      ],
      "metadata": {
        "id": "F3EZPA85KLlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaSnQy69JwL-",
        "outputId": "356b9637-86c4-4549-dde5-64dd15a2ad2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6,), (6,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "id": "ucQKLXQ7KAhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03316719-487f-47c7-c96b-f7a51d8a515b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(-7.0), np.float64(3.0))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxy8eKabTDaS",
        "outputId": "d4df29be-72a9-47c7-a4a2-f2efcc4360c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(6,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8.])>,\n",
              " <tf.Tensor: shape=(6,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyGjQxNYThCF",
        "outputId": "117fd8cd-54eb-401c-ce57-2ce43e6649ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,4))\n",
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "mW3rX-s0Tqzq",
        "outputId": "f7f39838-1964-49d6-d7d1-29ed225b99a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7e52a506d4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with tensorflow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss function (in other words, the functio which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model** - letting the model try to find patterns between X & y (features and labels)\n"
      ],
      "metadata": {
        "id": "SQbFEaErTwEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random_seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae, # mae is short for mean absolute error\n",
        "              optimizer = tf.keras.optimizers.SGD(), # sgd is short for stochastic gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kajowdNUrxL",
        "outputId": "28a93915-34af-47df-9eae-a76a1c726c81"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921ms/step - loss: 10.4738 - mae: 10.4738\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 10.4613 - mae: 10.4613\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 10.4488 - mae: 10.4488\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10.4363 - mae: 10.4363\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 10.4238 - mae: 10.4238\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e52a508b810>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkchcn-NWnUn",
        "outputId": "540ae113-6529-4691-933f-23e30d7816ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(6,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8.])>,\n",
              " <tf.Tensor: shape=(6,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a prediction using our model\n",
        "y_pred = model.predict(tf.constant([11.0]))\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_qMMu0FaWN-",
        "outputId": "9705b899-6585-4931-f0e8-74af7d04c19e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9011548]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "\n",
        "As we can above that from the above pattern at [11.0] our model predicted value should be 21....  but it is not giving exactly what we want.\n",
        "Hence, it's time to improve our model.\n",
        "\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. `Creating a model` - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. `Compiling a model` - here we might change the optimzation function or perhaps the **learning rate** of the optimzation function.\n",
        "3. `Fitting a model` - here we might fit a model for more **epochs** (leave it training for lomger) or on more data (give the model more examples to learn from)."
      ],
      "metadata": {
        "id": "k-p5J9LWaa_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the mode (this time we'll train for the longer time)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPagTgKb_wdr",
        "outputId": "2c1812d5-1d8a-45b2-8469-980ebe6f909e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - loss: 10.3128 - mae: 10.3128\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10.3003 - mae: 10.3003\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10.2878 - mae: 10.2878\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 10.2753 - mae: 10.2753\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 10.2628 - mae: 10.2628\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10.2503 - mae: 10.2503\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 10.2378 - mae: 10.2378\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10.2253 - mae: 10.2253\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10.2128 - mae: 10.2128\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 10.2003 - mae: 10.2003\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 10.1878 - mae: 10.1878\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 10.1753 - mae: 10.1753\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10.1628 - mae: 10.1628\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 10.1503 - mae: 10.1503\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 10.1378 - mae: 10.1378\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 10.1253 - mae: 10.1253\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 10.1128 - mae: 10.1128\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 10.1003 - mae: 10.1003\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 10.0878 - mae: 10.0878\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 10.0753 - mae: 10.0753\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 10.0628 - mae: 10.0628\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 10.0503 - mae: 10.0503\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 10.0378 - mae: 10.0378\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 10.0253 - mae: 10.0253\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10.0128 - mae: 10.0128\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 10.0003 - mae: 10.0003\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 9.9878 - mae: 9.9878\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 9.9753 - mae: 9.9753\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 9.9628 - mae: 9.9628\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 9.9503 - mae: 9.9503\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 9.9378 - mae: 9.9378\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 9.9253 - mae: 9.9253\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 9.9128 - mae: 9.9128\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 9.9003 - mae: 9.9003\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 9.8878 - mae: 9.8878\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 9.8753 - mae: 9.8753\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 9.8628 - mae: 9.8628\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 9.8503 - mae: 9.8503\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 9.8378 - mae: 9.8378\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 9.8253 - mae: 9.8253\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 9.8128 - mae: 9.8128\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 9.8003 - mae: 9.8003\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 9.7878 - mae: 9.7878\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 9.7753 - mae: 9.7753\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 9.7628 - mae: 9.7628\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 9.7503 - mae: 9.7503\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 9.7378 - mae: 9.7378\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 9.7253 - mae: 9.7253\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 9.7128 - mae: 9.7128\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 9.7003 - mae: 9.7003\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 9.6878 - mae: 9.6878\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 9.6753 - mae: 9.6753\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 9.6628 - mae: 9.6628\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 9.6503 - mae: 9.6503\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 9.6378 - mae: 9.6378\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.6253 - mae: 9.6253\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 9.6128 - mae: 9.6128\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 9.6003 - mae: 9.6003\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 9.5878 - mae: 9.5878\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 9.5753 - mae: 9.5753\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 9.5628 - mae: 9.5628\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9.5503 - mae: 9.5503\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.5378 - mae: 9.5378\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.5253 - mae: 9.5253\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 9.5128 - mae: 9.5128\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.5003 - mae: 9.5003\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 9.4878 - mae: 9.4878\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 9.4753 - mae: 9.4753\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.4628 - mae: 9.4628\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 9.4503 - mae: 9.4503\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9.4378 - mae: 9.4378\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9.4253 - mae: 9.4253\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.4128 - mae: 9.4128\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9.4003 - mae: 9.4003\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.3878 - mae: 9.3878\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 9.3753 - mae: 9.3753\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 9.3628 - mae: 9.3628\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.3503 - mae: 9.3503\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.3378 - mae: 9.3378\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 9.3253 - mae: 9.3253\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 9.3128 - mae: 9.3128\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.3003 - mae: 9.3003\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.2878 - mae: 9.2878\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 9.2753 - mae: 9.2753\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 9.2628 - mae: 9.2628\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.2503 - mae: 9.2503\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.2378 - mae: 9.2378\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.2253 - mae: 9.2253\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.2128 - mae: 9.2128\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.2003 - mae: 9.2003\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 9.1878 - mae: 9.1878\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 9.1753 - mae: 9.1753\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.1628 - mae: 9.1628\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 9.1503 - mae: 9.1503\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.1378 - mae: 9.1378\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.1253 - mae: 9.1253\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 9.1128 - mae: 9.1128\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.1003 - mae: 9.1003\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.0878 - mae: 9.0878\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.0753 - mae: 9.0753\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e52a0366d10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "par0vCIUEIum",
        "outputId": "f74f694b-cf4f-439d-995f-17663d61738a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(6,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8.])>,\n",
              " <tf.Tensor: shape=(6,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved\n",
        "model.predict(tf.constant([11.0]))  # Now we should get output close to 21"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAI1qROuEj_z",
        "outputId": "c34c3902-563c-44b6-e1d2-9861953b0d7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10.619163]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if we can make another to improve our model\n",
        "\n",
        "# 1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fitting the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y , epochs=100)"
      ],
      "metadata": {
        "id": "rCkwJOVgEt28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608ed5f4-6cf1-41b9-f0af-be649308e992"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800ms/step - loss: 10.9145 - mae: 10.9145\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 10.6828 - mae: 10.6828\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 10.4515 - mae: 10.4515\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 10.2206 - mae: 10.2206\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.9911 - mae: 9.9911\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.7603 - mae: 9.7603\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9.5271 - mae: 9.5271\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9.2941 - mae: 9.2941\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 9.0605 - mae: 9.0605\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 8.8236 - mae: 8.8236\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 8.5834 - mae: 8.5834\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 8.3405 - mae: 8.3405\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 8.0932 - mae: 8.0932\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7.8406 - mae: 7.8406\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 7.5823 - mae: 7.5823\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 7.3179 - mae: 7.3179\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.0471 - mae: 7.0471\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.8386 - mae: 6.8386\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.6398 - mae: 6.6398\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 6.4339 - mae: 6.4339\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.2204 - mae: 6.2204\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 5.9987 - mae: 5.9987\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.7687 - mae: 5.7687\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.5394 - mae: 5.5394\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.2953 - mae: 5.2953\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.0366 - mae: 5.0366\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 4.7670 - mae: 4.7670\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 4.4860 - mae: 4.4860\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 4.1938 - mae: 4.1938\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.8885 - mae: 3.8885\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.8664 - mae: 3.8664\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.8625 - mae: 3.8625\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.8692 - mae: 3.8692\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.8636 - mae: 3.8636\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.8581 - mae: 3.8581\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.8526 - mae: 3.8526\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8471 - mae: 3.8471\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 3.8416 - mae: 3.8416\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8362 - mae: 3.8362\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.8329 - mae: 3.8329\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.8393 - mae: 3.8393\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.8338 - mae: 3.8338\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.8284 - mae: 3.8284\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.8229 - mae: 3.8229\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.8175 - mae: 3.8175\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.8121 - mae: 3.8121\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.8067 - mae: 3.8067\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.8162 - mae: 3.8162\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.8279 - mae: 3.8279\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.8224 - mae: 3.8224\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.8168 - mae: 3.8168\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.8113 - mae: 3.8113\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.8059 - mae: 3.8059\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.8005 - mae: 3.8005\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.7951 - mae: 3.7951\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.7903 - mae: 3.7903\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 3.7981 - mae: 3.7981\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 3.7927 - mae: 3.7927\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.7873 - mae: 3.7873\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.7819 - mae: 3.7819\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.7765 - mae: 3.7765\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.7712 - mae: 3.7712\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.7659 - mae: 3.7659\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.7605 - mae: 3.7605\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.7688 - mae: 3.7688\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.7637 - mae: 3.7637\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.7586 - mae: 3.7586\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.7706 - mae: 3.7706\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.7651 - mae: 3.7651\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.7597 - mae: 3.7597\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.7543 - mae: 3.7543\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.7489 - mae: 3.7489\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.7550 - mae: 3.7550\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.7520 - mae: 3.7520\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.7466 - mae: 3.7466\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 3.7412 - mae: 3.7412\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.7359 - mae: 3.7359\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.7305 - mae: 3.7305\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.7252 - mae: 3.7252\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.7199 - mae: 3.7199\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.7249 - mae: 3.7249\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.7231 - mae: 3.7231\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.7178 - mae: 3.7178\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.7125 - mae: 3.7125\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.7072 - mae: 3.7072\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.7019 - mae: 3.7019\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.6966 - mae: 3.6966\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.7064 - mae: 3.7064\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.7108 - mae: 3.7108\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.7116 - mae: 3.7116\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.7061 - mae: 3.7061\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 3.7008 - mae: 3.7008\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.6954 - mae: 3.6954\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.6901 - mae: 3.6901\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.6848 - mae: 3.6848\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.6795 - mae: 3.6795\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.6802 - mae: 3.6802\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.6828 - mae: 3.6828\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.6774 - mae: 3.6774\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.6721 - mae: 3.6721\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e528e4d4ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr4plDOnMmo5",
        "outputId": "40136228-3f80-484b-e34b-5ca8162d9970"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(6,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8.])>,\n",
              " <tf.Tensor: shape=(6,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's predict now\n",
        "model.predict(tf.constant([11.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go8AI_YsMqcL",
        "outputId": "46247dce-2d04-42d0-a6eb-294faa8085fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24.80878]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a model"
      ],
      "metadata": {
        "id": "-2lXLMwcMy2T"
      }
    }
  ]
}